{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the next step, the last columns containg cordinates and population are included in the dataframe for each year before merging them into a single dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset for 2016 with skills. The whole process is repeated all years.\n",
    "df_16_skills = pd.read_csv('updated_job_listings_with_skills_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the geocoder\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "\n",
    "# Cache to store already processed locations\n",
    "location_cache = {}\n",
    "\n",
    "# Function to fetch latitude and longitude with caching and delay\n",
    "def fetch_coordinates(area_name):\n",
    "    if area_name in location_cache:\n",
    "        return location_cache[area_name]\n",
    "    try:\n",
    "        location = geolocator.geocode(area_name)\n",
    "        time.sleep(1)  # Delay to avoid rate-limiting\n",
    "        if location:\n",
    "            coords = (location.latitude, location.longitude)\n",
    "        else:\n",
    "            coords = (None, None)\n",
    "        location_cache[area_name] = coords\n",
    "        return coords\n",
    "    except Exception as e:\n",
    "        return (None, None)\n",
    "\n",
    "# Apply the function to the 'Area' column in the DataFrame\n",
    "df_16_skills['Coordinates'] =df_16_skills['Area'].apply(fetch_coordinates)\n",
    "df_16_skills['Latitude'] = df_16_skills['Coordinates'].apply(lambda x: x[0])\n",
    "df_16_skills['Longitude'] = df_16_skills['Coordinates'].apply(lambda x: x[1])\n",
    "\n",
    "# Drop the intermediate 'Coordinates' column\n",
    "df_16_skills = df_16_skills.drop(columns=['Coordinates'])\n",
    "\n",
    "# Looking at the first few rows of the dataset\n",
    "df_16_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of Enligsh to Danish city names as the API does not recognize English names\n",
    "\n",
    "city_name_mapping = {\n",
    "    'Copenhagen': 'København',\n",
    "    'Aarhus': 'Århus',\n",
    "    'Elsinore': 'Helsingør'\n",
    "}\n",
    "\n",
    "df_16_skills['Area'] = df_16_skills['Area'].replace(city_name_mapping)\n",
    "\n",
    "# call Århus for Aarhus\n",
    "df_16_skills['Area'] = df_16_skills['Area'].replace('Århus', 'Aarhus')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Define the parameters for the population data request\n",
    "params = {\n",
    "    'table': 'FOLK1A',  # Table for population\n",
    "    'format': 'BULK',\n",
    "    'variables': [\n",
    "        {'code': 'OMRÅDE', 'values': ['*']},  # All areas\n",
    "        {'code': 'Tid', 'values': [f'{year}K1' for year in range(2016, 2025)]},  # First quarter of each year from 2016 to 2024\n",
    "        {'code': 'KØN', 'values': ['TOT']},  # Total population (ignore gender)\n",
    "        {'code': 'ALDER', 'values': ['IALT']},  # All ages\n",
    "        {'code': 'CIVILSTAND', 'values': ['TOT']}  # Total population (ignore marital status)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.post('https://api.statbank.dk/v1/data', json=params)\n",
    "data = response.text\n",
    "\n",
    "# Check for errors in the response\n",
    "if 'errorTypeCode' in data:\n",
    "    print(\"Error:\", data)\n",
    "else:\n",
    "    # Load the response into a pandas DataFrame\n",
    "    population = pd.read_csv(StringIO(data), sep=';')\n",
    "\n",
    "    # Clean column names by stripping spaces\n",
    "    population.columns = population.columns.str.strip()\n",
    "\n",
    "    # Filter the columns to focus on 'OMRÅDE', 'TID', and 'INDHOLD' (which contains population)\n",
    "    population = population[['OMRÅDE', 'TID', 'INDHOLD']]\n",
    "\n",
    "    # Convert 'INDHOLD' to numeric\n",
    "    population['INDHOLD'] = pd.to_numeric(population['INDHOLD'], errors='coerce')\n",
    "\n",
    "    # Extract the year from 'TID' and group by area and year\n",
    "    population['Year'] = population['TID'].str[:4]  # Extract year from 'TID'\n",
    "    population_grouped = population.groupby(['OMRÅDE', 'Year'])['INDHOLD'].sum().reset_index()\n",
    "\n",
    "    # Function to get population based on area and published year\n",
    "    def get_population(location, published_date):\n",
    "        year = published_date[:4]  # Extract the year from the published date\n",
    "        matched_row = population_grouped[\n",
    "            (population_grouped['OMRÅDE'] == location) &\n",
    "            (population_grouped['Year'] == year)\n",
    "        ]\n",
    "        if not matched_row.empty:\n",
    "            return matched_row.iloc[0]['INDHOLD']\n",
    "        return None\n",
    "\n",
    "    # Apply the function to add the 'Population' column\n",
    "    df_16_skills['Population'] = df_16_skills.apply(\n",
    "        lambda row: get_population(row['Area'], row['Published']), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the first few rows of the dataset with population data included \n",
    "df_16_skills.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the names of cites where the population is nan\n",
    "df_16_skills[df_16_skills['Population'].isnull()]['Area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dictionary with population values for specific cities where the API did not return data\n",
    "specific_population = {\n",
    "    'Lyngby': 58538,\n",
    "    'Taastrup': 57540,\n",
    "    'Nørresundby': 24281,\n",
    "    'Farum': 20426,\n",
    "    'Birkerød': 20921,\n",
    "    'Lillerød': 16801,\n",
    "    'Frederiksværk': 12864,\n",
    "}\n",
    "\n",
    "# Fill missing population values (NaN) in the 'Population' column\n",
    "df_16_skills['Population'] = df_16_skills.apply(\n",
    "    lambda row: specific_population[row['Area']] if pd.isna(row['Population']) and row['Area'] in specific_population else row['Population'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df_16_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking into the final dataset for 2016\n",
    "df_16_skills.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn df_16_skills into a csv file which will be used to create the final dataset. \n",
    "# The whole process is repeated for the other years as well.\n",
    "\n",
    "df_16_skills.to_csv('updated_job_listings_with_skills_2016.csv', index=False)\n",
    "df_17_skills.to_csv('updated_job_listings_with_skills_2017.csv', index=False)\n",
    "df_18_skills.to_csv('updated_job_listings_with_skills_2018.csv', index=False)\n",
    "df_19_skills.to_csv('updated_job_listings_with_skills_2019.csv', index=False)\n",
    "df_20_skills.to_csv('updated_job_listings_with_skills_2020.csv', index=False)\n",
    "df_21_skills.to_csv('updated_job_listings_with_skills_2021.csv', index=False)\n",
    "df_22_skills.to_csv('updated_job_listings_with_skills_2022.csv', index=False)\n",
    "df_23_skills.to_csv('updated_job_listings_with_skills_2023.csv', index=False)\n",
    "df_24_skills.to_csv('updated_job_listings_with_skills_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into one\n",
    "df = pd.concat([df_16_skills, df_17_skills, df_18_skills, df_19_skills, df_20_skills, df_21_skills, df_22_skills, df_23_skills, df_24_skills], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file which will be used for our streamlit app\n",
    "df.to_csv('df_2016_2024.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
